### 分类模型评估API

- sklearn.metrics.classification_report(y_true, y_pred, target_names=None)
  - y_true：真是目标值
  - y_pred：估计器预测目标值
  - target_names：目标类别名称
  - return：每个类别精确率与召回率









## 模型的选择与调优

1. 交叉验证

   1. 目的：为了让被评估的模型更加准确可信
   2. 将所有数据分成若干等份，然后取其中一份为验证集，其余为训练集。依次让每一份作为验证集，其余为训练集。最后获得不同的模型，得出一个准确率，最后讲准确率取其平均值。例如，我们将数据分为5份，先取第一份为验证集，其余四份为训练集，得到一个模型准确率，然后取第二份为验证集，其余为训练集，得到一个模型的准确率。按照这个规律依次取其他部分为验证集和训练集。最后将所有模型的准确率的取平均值得到最后的准确率。分为几等份就问几折交叉验证

2. 超参数搜索-网格搜索（调参数）

   1. API    `sklearn.model_selection.GridSearchCV(estimator, param_grid=None,cv=None)`

      - 对估计器的指定参数值进行详尽搜索

      - estimator：估计器参数(dict){"n_neighbors":[1,3,5]}

      - cv：指定几折交叉验证

      - fit：输入训练数据

      - score：准确率

      - 结果分析：

      - best_score_：在交叉验证中验证的最好结果

      - best_estimator_：最好的参数模型

      - ##### cv_results_：每次交叉验证后的测试集准确率结果和训练集准确率结果