###  朴素贝叶斯公式


$$
P(C|W)=\frac{P(W|C)P(C)}{P(W)}
$$
注：w为给定文档的特征值（频数统计，预测文档提供），c为文档类别。

公式可理解为：
$$
P(C|F1,F2,...)=\frac{P(F1,F2,...|C)P(C)}{P(F1,F2,...)}
$$
其中c可以是不同类别。

公式分为三个部分：

- P(C)：每个文档类别的概率（某文档类别数/总文档数）

- P(W|C)：给定类别下特征（被预测文档中出现的词）的概率

  计算方法：P(F1|C) = Ni/N         **训练文档中去计算**

  Ni为该F1词在C类别所有文档中出现的次数

  N为所属类别C下的文档所有词出现的次数和 

- P(F1,F2,...)   预测文档中每个词的概率



例子：

​	现有一篇被预测的文档，出现了影院，支付宝，云计算，计算属于科技、娱乐的类别概率。

| 特征/统计  | 科技(30篇) | 娱乐(60篇) | 汇总(90篇) |
| :--------: | :--------: | :--------: | :--------: |
|    商场    |     9      |     51     |     60     |
|    影院    |     8      |     56     |     64     |
|   支付宝   |     20     |     15     |     35     |
|   云计算   |     63     |     0      |     63     |
| 汇总(求和) |    100     |    121     |    221     |

科技的类别概率：

​				P(科技|影院，支付宝，云计算) = P(影院，支付宝，云计算|科技)P(科技)

​																			  =(8/100)(20/100)(63/100)(30/90)=0.00456109

​				P(娱乐|影院，支付宝，云计算) = P(影院，支付宝，云计算|娱乐)P(娱乐)

​																		      =(56/121)(15/121)(0/121)(60/90)=0





### 拉普拉丝平滑

​	由上面例子可以看到，娱乐类别的概率为0，这显然是不合适的，也不科学的。为了解决这一问题，我们可以在式子中加上拉普拉斯平滑系数。公式如下：
$$
P(F1|C)=\frac{Ni+\alpha}{N+\alpha m}
$$
α为指定的系数一般为1，m为训练文档中统计出的特征词的个数。

上面娱乐类别的概率就可以写成：P=(56+1/121+1*4)(15+1/121+1*4)(0+1/121+1*4)(60/90)=0.001

同样科技类的也要做修改，这里就不演示了，步骤相同。



###       sklearn朴素贝叶斯的API

`sklearn.naive_bayes.MultinomialNB`



### 朴素贝叶斯的优缺点

1. 优点
   - 朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率
   - 对缺失数据不太敏感，算法也比较简单，常用于分类
   - 分类的准确率高，速度快
2. 缺点
   - 由于使用了样本属性独立性的假设，所有如果样本属性有关联时其效果不好。