#### tensorflow填充与复制

- pad

  对tensor进行pad填充，以这个`[[],[]]`格式对其进行填充，里面第一个方括号是对行的上下进行填充，数值为几就填充几行（默认填充0，第一个数字填充上方，第二个数字填充下方）；第二个方括号填充列，里面第一个数字填充左边，第二个填充右边。

  ```python
  In [3]: a                                                                       
  Out[3]: 
  <tf.Tensor: id=5, shape=(3, 3), dtype=int32, numpy=
  array([[0, 1, 2],
         [3, 4, 5],
         [6, 7, 8]], dtype=int32)>
  
  In [4]: tf.pad(a, [[1,1],[0,2]])    # 上边和下边行各添加一行，左边不添加，右边添加两行                                            
  Out[4]: 
  <tf.Tensor: id=8, shape=(5, 5), dtype=int32, numpy=
  array([[0, 0, 0, 0, 0],
         [0, 1, 2, 0, 0],
         [3, 4, 5, 0, 0],
         [6, 7, 8, 0, 0],
         [0, 0, 0, 0, 0]], dtype=int32)>
  
  
  In [2]: a = tf.random.normal([4,28,28,3])
  In [3]: b = tf.pad(a, [[0, 0], [2, 2], [2, 2], [0, 0]])                                                                                                             
  
  In [4]: b.shape                                                                                                                                                     
  Out[4]: TensorShape([4, 32, 32, 3])
  ```

  

- tile

  绕着不同纬度进行复制，如下例。[1,2]分别表示对行不进行复制，对列进行复制一次（为1表示不进行复制）

  ```python
  In [8]: a                                                                       
  Out[8]: 
  <tf.Tensor: id=5, shape=(3, 3), dtype=int32, numpy=
  array([[0, 1, 2],
         [3, 4, 5],
         [6, 7, 8]], dtype=int32)>
  
  In [9]: tf.tile(a, [1,2])                                                       
  Out[9]: 
  <tf.Tensor: id=16, shape=(3, 6), dtype=int32, numpy=
  array([[0, 1, 2, 0, 1, 2],
         [3, 4, 5, 3, 4, 5],
         [6, 7, 8, 6, 7, 8]], dtype=int32)>
  
  ```

  

- broadcast_to

---

#### 张量的限幅

- clip_by_value

  我们在对输入进行限幅的时候，比如`tf.maximum(x, y)`和`tf.minimun(x, y)`可以简单的实现单方向的限制，像relu这种。但是我们要同时进行两边都限制的时候，比如输入在2~8这个范围都可以输出他本来的数字，在输入<2或者>8的时候输出2和8。这种情况我们可以通过上面两种方式进行组合，但是比较不方便。

  `clip_by_value`可以很好的解决这个问题。它通过传入三个参数(a, x, y)，a为传入的tensor，x和y为需要限幅的下限和上限。

  ```
  In [13]: a                                                                      
  Out[13]: <tf.Tensor: id=27, shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>
  
  In [16]: tf.clip_by_value(a, 2, 8)                                              
  Out[16]: <tf.Tensor: id=38, shape=(10,), dtype=int32, numpy=array([2, 2, 2, 3, 4, 5, 6, 7, 8, 8], dtype=int32)>
  
  ```

  

- relu

  `tf.nn.rule()`传入一个参数，实现`relu`函数

- clip_by_norm

  改变向量的模大小（范数），而不改变向量的方向

  ```python
  In [17]: a = tf.random.normal([2,2], mean=10)                                   
  
  In [18]: a                                                                      
  Out[18]: 
  <tf.Tensor: id=45, shape=(2, 2), dtype=float32, numpy=
  array([[11.728876, 11.391424],
         [12.097851, 10.988718]], dtype=float32)>
  
  In [19]: tf.norm(a)                                                             
  Out[19]: <tf.Tensor: id=51, shape=(), dtype=float32, numpy=23.11798>
  
  In [20]: tf.clip_by_norm(a, 15)                                                 
  Out[20]: 
  <tf.Tensor: id=69, shape=(2, 2), dtype=float32, numpy=
  array([[7.61023  , 7.3912764],
         [7.8496375, 7.1299815]], dtype=float32)>
  
  In [21]: tf.norm(tf.clip_by_norm(a, 15))                                        
  Out[21]: <tf.Tensor: id=92, shape=(), dtype=float32, numpy=15.000001>
  
  
  ```

- gradient clipping 

  梯度裁剪，可以解决梯度爆炸和梯度消失。

  ```python
  new_grads, total_norm = tf.clip_by_global_norm(grads, 25)
  ```

  对norm进行等比例缩放，且不改变方向。`grads`是所有参数的gradient，25是对所有参数之和的norm值。

  返回两个值，new_grads是缩放后新的norm，total_nrom是之前所有的norm。





1. `tf.maximum(x, y)`

   返回 x 和 y 的最大值(即表达式：x > y ? x : y).

2. `tf.minimun(x, y)`

   返回 x 和 y 的最小值(即表达式：x < y ? x : y).

   例如：

   ```
   In [12]: a = tf.constant(tf.range(10))                                          
   
   In [13]: a                                                                      
   Out[13]: <tf.Tensor: id=27, shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>
   
   In [14]: tf.maximum(a,2)                                                        
   Out[14]: <tf.Tensor: id=30, shape=(10,), dtype=int32, numpy=array([2, 2, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>
   
   In [15]: tf.minimum(a,2)                                                        
   Out[15]: <tf.Tensor: id=33, shape=(10,), dtype=int32, numpy=array([0, 1, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>
   
   ```



#### 其他高阶操作

1. 坐标操作

   - where	

     当传入的参数为一个的时候，`tf.where(a)`通过a传入一个true和false的tensor，然后返回一个为true的坐标位置

     ```
     In [3]: a                                                                       
     Out[3]: 
     <tf.Tensor: id=5, shape=(3, 3), dtype=float32, numpy=
     array([[-1.0460997 , -1.3858232 ,  0.36873293],
            [ 0.73845226, -0.49485523, -0.01161941],
            [-1.5307101 ,  1.5128095 , -0.17678499]], dtype=float32)>
     
     In [4]: mask=a>0                                                                
     
     In [5]: mask                                                                    
     Out[5]: 
     <tf.Tensor: id=8, shape=(3, 3), dtype=bool, numpy=
     array([[False, False,  True],
            [ True, False, False],
            [False,  True, False]])>
     
     In [7]: tf.where(mask)                                                          
     Out[7]: 
     <tf.Tensor: id=38, shape=(3, 2), dtype=int64, numpy=
     array([[0, 2],
            [1, 0],
            [2, 1]])>
     
     可以通过他返回的坐标，再找到他之前在tensor中的数字
     In [10]: tf.gather_nd(a, tf.where(mask))                                        
     Out[10]: <tf.Tensor: id=44, shape=(3,), dtype=float32, numpy=array([0.36873293, 0.73845226, 1.5128095 ], dtype=float32)>
     
     当然实现这中操作的方式不止这一种，也可以通过tf.boolean_mask()实现
     In [6]: tf.boolean_mask(a, mask)                                                
     
     Out[6]: <tf.Tensor: id=36, shape=(3,), dtype=float32, numpy=array([0.36873293, 0.73845226, 1.5128095 ], dtype=float32)>
     
     ```

     2. 当传入的为三个参数(cond, A, B)（一个true和false组成的tensor，另外两个为数字tensor，三个参数传入的shape是一样的）

        如果在cond中其位置是true那么对应在A的位置选其元素，如果为False则在B对应其位置选

        

   - scatter_nd

     `tf.scatter_nd(indices, updates, shape)`
   
     将update中的数据，根据indices中的索引更新到shape中去
   
     ```python
     In [2]: indices = tf.constant([[4], [3], [1], [7]]) 
     In [3]: updates = tf.constant([9, 10, 11, 12])                                                                                                                      
     
     In [4]: shape = tf.constant([8])                                                                                                                                    
     
     In [5]: tf.scatter_nd(indices, updates, shape)                                                                                                                      
     Out[5]: <tf.Tensor: shape=(8,), dtype=int32, numpy=array([ 0, 11,  0, 10,  9,  0,  0, 12], dtype=int32)>
     ```
   
     ![](https://tva1.sinaimg.cn/large/006tNbRwly1gben4abmf2j31go0ns0w1.jpg)
   
   - meshgrid
   
     生成坐标轴
   
     ```python
     In [11]: y = tf.linspace(-2., 2, 5)                                                                                                                                 
     # 生成-2~2，一共5个点的array数组
     In [12]: y                                                                                                                                                          
     Out[12]: <tf.Tensor: shape=(5,), dtype=float32, numpy=array([-2., -1.,  0.,  1.,  2.], dtype=float32)>
         
     In [14]: x = tf.linspace(-2., 2, 5)                                                                                                                                 
     
     In [15]: x                                                                                                                                                          
     Out[15]: <tf.Tensor: shape=(5,), dtype=float32, numpy=array([-2., -1.,  0.,  1.,  2.], dtype=float32)>
         
     In [16]: points_x, points_y = tf.meshgrid(x, y)                                                                                                                     
     
     In [17]: points_x                                                                                                                                                   
     Out[17]: 
     <tf.Tensor: shape=(5, 5), dtype=float32, numpy=
     array([[-2., -1.,  0.,  1.,  2.],
            [-2., -1.,  0.,  1.,  2.],
            [-2., -1.,  0.,  1.,  2.],
            [-2., -1.,  0.,  1.,  2.],
            [-2., -1.,  0.,  1.,  2.]], dtype=float32)>
     
     In [18]: points_y                                                                                                                                                   
     Out[18]: 
     <tf.Tensor: shape=(5, 5), dtype=float32, numpy=
     array([[-2., -2., -2., -2., -2.],
            [-1., -1., -1., -1., -1.],
            [ 0.,  0.,  0.,  0.,  0.],
            [ 1.,  1.,  1.,  1.,  1.],
            [ 2.,  2.,  2.,  2.,  2.]], dtype=float32)>
     ```
   
     将point_x和point_y组合起来就是一个完整的坐标。
   
     